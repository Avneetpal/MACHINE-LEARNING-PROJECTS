{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88e1fcfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kata': 16, 'code': 12, 'challeng': 12, 'codewar': 7, 'new': 7, 'develop': 6, 'honor': 6, 'commun': 6, 'differ': 5, 'languag': 5, 'rank': 4, 'skill': 4, 'push': 4, 'techniqu': 4, 'solut': 4, 'other': 4, 'creat': 4, 'practic': 3, 'earn': 3, 'level': 3, 'masteri': 2, 'dojo': 2, 'librarycomplet': 2, 'leaderboardsachiev': 2, 'move': 2, 'leaderboard': 2, 'docslearn': 2, 'aspect': 2, 'codewarsblogfor': 2, 'educatorsfor': 2, 'companieslog': 2, 'masterythrough': 2, 'train': 2, 'master': 2, 'program': 2, 'get': 2, 'right': 2, 'use': 2, 'progress': 2, 'creativ': 2, 'beginn': 2, 'expert': 2, 'complet': 2, 'softwar': 2, 'collect': 2, 'solv': 2, 'member': 2, 'everi': 2, 'understand': 2, 'limit': 2, 'world': 2, 'well': 2, 'contribut': 2, 'corner': 2, 'greenemay': 2, 'introduc': 2, 'epic': 2, 'andela': 2, 'achiev': 1, 'mentorship': 1, 'injoindojo': 1, 'injoinachiev': 1, 'challengeimprov': 1, 'peer': 1, 'continu': 1, 'start': 1, 'sharpen': 1, 'skillschalleng': 1, 'small': 1, 'exercis': 1, 'call': 1, 'craft': 1, 'help': 1, 'strengthen': 1, 'current': 1, 'choic': 1, 'quickli': 1, 'pick': 1, 'instant': 1, 'feedbacksolv': 1, 'style': 1, 'browser': 1, 'test': 1, 'case': 1, 'tdd': 1, 'check': 1, 'retrain': 1, 'optim': 1, 'approach': 1, 'find': 1, 'bug': 1, 'honorkata': 1, 'profil': 1, 'highest': 1, 'engag': 1, 'communitycodewar': 1, 'effort': 1, 'user': 1, 'teach': 1, 'variou': 1, 'enlighten': 1, 'comment': 1, 'construct': 1, 'ad': 1, 'tap': 1, 'wisdomcompar': 1, 'greater': 1, 'discuss': 1, 'best': 1, 'innov': 1, 'mind': 1, 'blown': 1, 'kataauthor': 1, 'focu': 1, 'interest': 1, 'specif': 1, 'set': 1, 'insight': 1, 'everyth': 1, 'common': 1, 'interview': 1, 'question': 1, 'gain': 1, 'within': 1, 'beyond': 1, 'perspectivessolv': 1, 'view': 1, 'pickup': 1, 'learn': 1, 'languagessolv': 1, 'comfort': 1, 'want': 1, 'improv': 1, 'across': 1, 'compet': 1, 'peerscompet': 1, 'friend': 1, 'colleagu': 1, 'larg': 1, 'allow': 1, 'competit': 1, 'motiv': 1, 'â': 1, 'toward': 1, 'done': 1, 'excel': 1, 'exampl': 1, 'omran': 1, 'got': 1, 'addict': 1, 'williamscod': 1, 'build': 1, 'sure': 1, 'programm': 1, 'show': 1, 'realli': 1, 'made': 1, 'becom': 1, 'mentorlend': 1, 'expertis': 1, 'either': 1, 'indirectli': 1, 'great': 1, 'directli': 1, 'review': 1, 'latestinsight': 1, 'staff': 1, 'cornerauthor': 1, 'meet': 1, 'seri': 1, 'spotlight': 1, 'excit': 1, 'newswhat': 1, 'april': 1, 'highlightswelcom': 1, 'back': 1, 'highlight': 1, 'engin': 1, 'team': 1, 'vanessa': 1, 'greeneapril': 1, 'isâ': 1, 'built': 1, 'onth': 1, 'advanc': 1, 'assess': 1, 'platform': 1, 'organ': 1, 'look': 1, 'scale': 1, 'hire': 1, 'upskil': 1, 'certif': 1, 'moreachiev': 1, 'languagescc': 1, 'libraryleaderboarddocsdevelopersblogpartn': 1, 'schoolsmissionsprevieweducatorseduc': 1, 'partnershipscompaniesskil': 1, 'policyterm': 1, 'serviceabout': 1}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "\n",
    "\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "def extract_keywords_from_url(url):\n",
    "    response = requests.get(url)\n",
    "    content = response.text\n",
    "\n",
    "    \n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    text = soup.get_text()\n",
    "\n",
    "    \n",
    "    tokens = word_tokenize(text.lower())\n",
    "\n",
    "    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
    "\n",
    "    \n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "\n",
    "    word_counts = Counter(stemmed_words)\n",
    "\n",
    "    \n",
    "    keywords = {word: count for word, count in word_counts.items()}\n",
    "\n",
    "    \n",
    "    sorted_keywords = dict(sorted(keywords.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "    return sorted_keywords\n",
    "\n",
    "\n",
    "url = 'https://www.codewars.com/'  \n",
    "keywords = extract_keywords_from_url(url)\n",
    "print(keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0421c896",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
